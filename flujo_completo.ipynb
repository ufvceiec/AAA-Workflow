{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importación de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import workflow as wf\n",
    "import shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recarga del script en el noteook si se realizan cambios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(wf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga y preprocesamiento de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Path a los datos y variable obetivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"REGISTRO  FERNANDO PARA IA.xls\"\n",
    "target = \"EXITUS30D\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carga de los datos y estandarización de los mismos:\n",
    "- missing values: [' ', 'NaN', 'na', 'Na', '-', '--', 'n/a']\n",
    "- bools: ['Sí', 'sí', 'SI', 'Si'] -> 'si', lo mismo para 'No'\n",
    "- lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_raw = wf.load_and_clean(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eliminación de aquellas columnas no relevantes para el estudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_raw = wf.drop_initials_columns(datos_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Codificación de los datos, tres técnicas disponibles:\n",
    "- Para utilizar técnicas de muestreo:\n",
    "  - ordinal encoding - `wf.ordinal_encoding()`\n",
    "- Para entrenar directamente los modelos neuronales\n",
    "  - binary enconding - `wf.binary_encoding()`\n",
    "  - one hot encoding - `wf.one_hot_encoding()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_encoded = wf.ordinal_encoding(datos_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estudio de correlación de los datos:\n",
    "- Test de Kruskal-Wallis para conjuntos de datos numéricos y categóricos - `wf.kruskal_wallis_test()` (Si Plot=True, mostramos en el output el p-valor de cada variable)\n",
    "- Test Chi-cuadrado para conjuntos de datos categóricos - `wf.chi_squared_test()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_kruskal = wf.kruskal_wallis_test(data_encoded, target, plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_kruskal.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test para la selección de porcentae máximo de missing values y técnica de imputación de los mismos:\n",
    "- Porcentajes de missing values a probar: 5%, 10%, 15%, 20%, 40% y 60%\n",
    "- Técnicas de imputación aplicadas:\n",
    "  - Media\n",
    "  - Moda\n",
    "  - K Nearest Neighbors\n",
    "  - Random Forest\n",
    "- Cálculo de MSE para validar cada una de las combinaciones posibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wf.imputation_tests(datos_kruskal, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eliminación de missing values en función del porcentaje máximo permitido seleccionado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dropped = wf.drop_missing_values_columns(datos_kruskal, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dropped.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputación de los missing values restantes aplicando la técnica con mejores resultados del test\n",
    "- Opciones:\n",
    "    - `wf.mode_imputation()`\n",
    "    - `wf.mean_imputation()`\n",
    "    - `wf.knn_imputation()`\n",
    "    - `wf.random_forest_imputation()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_mode = wf.mode_imputation(data_dropped, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Guardado de los datos limpios, codificados y sin ningún missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_mode.to_excel('datasets_generados/datos_codificados_y_rellenados.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalización o Estandarización de los datos a una misma escala\n",
    "- Opciones posibles:\n",
    "    - MinMax normalization (`wf.min_max_normalization()`)\n",
    "    - Standard Scaler (`wf.standar_scaler()`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_normalize = wf.min_max_normalization(datos_mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Guardado de los datos normalizados o estandarizados (cambiar nombre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_normalize.to_excel('datasets_generados/datos_normalizados.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creación de los conjuntos de test con datos originales, antes de aplicar el muestreo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_original = data_normalize[data_normalize[target]==1]\n",
    "x_test_original = x_test_original.append(data_normalize[data_normalize[target]==0])\n",
    "x_test_original = x_test_original.iloc[0:58]\n",
    "y_test_original = x_test_original[target]\n",
    "x_test_original = x_test_original.drop(columns=[target])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparación de los datos y creación de conjuntos de train y test de cara al entrenamiento de los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_normalize_dropped = data_normalize.drop(columns = [target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test, network_output = wf.prep_datos_red(target , data_normalize, data_normalize_dropped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search para la búsqueda de los mejores parámetros:\n",
    "- Para establecer o modificar estos ir a `def grid_search_mlp()` en `workflow.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = wf.grid_search_mlp(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parámetros seleccionados manualmente para saltar el proceso del Grid Search en reiteradas ocasiones,  saltar a la línea siguiente al ejecutar para seleccionar los mejores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {'batch_size': 16, 'dropout_rate': 0.2, 'epochs': 50, 'neurons': 12}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compatibilidad de los modelos tanto con TensorFlow 1.0 como con 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf.tf.compat.v1.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Limpiamos todos aquellos modelos que se han quedado guardados en memoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf.tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrenamiento de múltiples MLPs y guardado de los mismos\n",
    "- n = 10 es el número de modelos a entrenar\n",
    "- patience = 5 es el parámetro para `wf.tf.keras.callbacks.EarlyStopping`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf.train_multiple_models(x_train, y_train, x_test_original, y_test_original, 10, best_params, 'models/normal/model_', 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carga de los modelos desde el path donde están almacenados y realización de la media entre las capas de los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = wf.load_and_ensemble_best_model(10, 'models/normal/model_', plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrenamiento del mejor modelo sobre el conjunto de train generado anteriormente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_model_train = wf.train_model(best_model, best_params, x_train, y_train, patience=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicción sobre el conjunto de datos originales:\n",
    "- Obtención de las métricas de:\n",
    "    - Accuracy\n",
    "    - Precision\n",
    "    - Recall\n",
    "    - F1 Score\n",
    "- Matriz de Confusión(TP, TN, FP, FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = wf.predict_model_and_report(best_model, x_test_original, y_test_original, ['exitus', 'no exitus'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE + Tomed Links data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aplicación de la técnicas de muestro para desbalancear los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_balanced = wf.smote_tomed_link(data_normalize, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_balanced[target].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_balanced.to_excel('datasets_generados/datos_balanceados_smote_tomed_links.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparación de los datos y creación de conjuntos de train y test de cara al entrenamiento de los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_balanced_dropped = data_balanced.drop(columns = [target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test, network_output = wf.prep_datos_red(target , data_balanced, data_balanced_dropped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search para la búsqueda de los mejores parámetros:\n",
    "- Para establecer o modificar estos ir a `def grid_search_mlp()` en `workflow.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = wf.grid_search_mlp(x_train, y_train, x_test_original, y_test_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parámetros seleccionados manualmente para saltar el proceso del Grid Search en reiteradas ocasiones,  saltar a la línea siguiente al ejecutar para seleccionar los mejores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {'batch_size': 16, 'dropout_rate': 0.25, 'epochs': 50, 'neurons': 8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compatibilidad de los modelos tanto con TensorFlow 1.0 como con 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf.tf.compat.v1.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Limpiamos todos aquellos modelos que se han quedado guardados en memoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf.tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrenamiento de múltiples MLPs y guardado de los mismos\n",
    "- n = 10 es el número de modelos a entrenar\n",
    "- patience = 5 es el parámetro para `wf.tf.keras.callbacks.EarlyStopping`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf.train_multiple_models(x_train, y_train, x_test_original, y_test_original, 10, best_params, 'models/normal/model_', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carga de los modelos desde el path donde están almacenados y realización de la media entre las capas de los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = wf.load_and_ensemble_best_model(10, 'models/normal/model_', plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrenamiento del mejor modelo sobre el conjunto de train generado anteriormente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_model_train = wf.train_model(best_model, best_params, x_train, y_train, patience=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicción sobre el conjunto de datos originales:\n",
    "- Obtención de las métricas de:\n",
    "    - Accuracy\n",
    "    - Precision\n",
    "    - Recall\n",
    "    - F1 Score\n",
    "- Matriz de Confusión(TP, TN, FP, FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = wf.predict_model_and_report(best_model, x_test_original, y_test_original, ['exitus', 'no exitus'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE + ENN data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aplicación de la técnicas de muestro para desbalancear los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_balanced = wf.smote_edited_nearest_neighbor(data_normalize, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_balanced.to_excel('datasets_generados/datos_balanceados_smote_enn.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_balanced[target].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparación de los datos y creación de conjuntos de train y test de cara al entrenamiento de los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_balanced_dropped = data_balanced.drop(columns = [target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test, network_output = wf.prep_datos_red(target , data_balanced, data_balanced_dropped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search para la búsqueda de los mejores parámetros:\n",
    "- Para establecer o modificar estos ir a `def grid_search_mlp()` en `workflow.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = wf.grid_search_mlp(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parámetros seleccionados manualmente para saltar el proceso del Grid Search en reiteradas ocasiones,  saltar a la línea siguiente al ejecutar para seleccionar los mejores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {'batch_size': 16, 'dropout_rate': 0.3, 'epochs': 50, 'neurons': 12}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compatibilidad de los modelos tanto con TensorFlow 1.0 como con 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf.tf.compat.v1.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Limpiamos todos aquellos modelos que se han quedado guardados en memoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf.tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrenamiento de múltiples MLPs y guardado de los mismos\n",
    "- n = 10 es el número de modelos a entrenar\n",
    "- patience = 5 es el parámetro para `wf.tf.keras.callbacks.EarlyStopping`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf.train_multiple_models(x_train, y_train, x_test_original, y_test_original, 10, best_params, 'models/normal/model_', 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carga de los modelos desde el path donde están almacenados y realización de la media entre las capas de los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = wf.load_and_ensemble_best_model(10, 'models/normal/model_', plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrenamiento del mejor modelo sobre el conjunto de train generado anteriormente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_model_train = wf.train_model(best_model, best_params, x_train, y_train, patience=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicción sobre el conjunto de datos originales:\n",
    "- Obtención de las métricas de:\n",
    "    - Accuracy\n",
    "    - Precision\n",
    "    - Recall\n",
    "    - F1 Score\n",
    "- Matriz de Confusión(TP, TN, FP, FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = wf.predict_model_and_report(best_model_train, x_test_original, y_test_original, ['exitus', 'no exitus'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shap Deep Explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_explainer, deep_values, x_train_deep_df = wf.shap_deep_explainer(data_balanced_dropped, x_train, x_test_original, best_model_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Force Plot que representa los valores de Shappley para cada atributo a lo largo de todas las predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(deep_explainer.expected_value, deep_values[0], x_train_deep_df, link=\"logit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot con el sumatorio de los valores de Shappley para cada atributo, obteniendo como resultado las características más importantes en las decisiones de los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf.shap_summary_plot(deep_values, x_train_deep_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creación de los conjuntos de datos(train) a partir de este subconjunto de características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_features, deep_features_drop, features = wf.features_df(data_balanced, deep_values, 8, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conjuntos de test tras la reducción de las características o variables menos influyentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_original_df = x_test_original[features]\n",
    "y_test_original_df = y_test_original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparación de los datos y creación de conjuntos de train y test de cara al entrenamiento de los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_df, x_test_df, y_train_df, y_test_df, network_output_df = wf.prep_datos_red(target, deep_features, deep_features_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Limpiamos todos aquellos modelos que se han quedado guardados en memoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrenamiento de múltiples MLPs y guardado de los mismos\n",
    "- n = 10 es el número de modelos a entrenar\n",
    "- patience = 5 es el parámetro para `wf.tf.keras.callbacks.EarlyStopping`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf.train_multiple_models(x_train_df, y_train_df, x_test_original_df, y_test_original_df, 10, best_params, 'models/features/model_', 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carga de los modelos desde el path donde están almacenados y realización de la media entre las capas de los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = wf.load_and_ensemble_best_model(10, 'models/features/model_', plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrenamiento del mejor modelo sobre el conjunto de train generado anteriormente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_model_train_df = wf.train_model(best_model, best_params, x_train_df, y_train_df, patience=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicción sobre el conjunto de datos originales:\n",
    "- Obtención de las métricas de:\n",
    "    - Accuracy\n",
    "    - Precision\n",
    "    - Recall\n",
    "    - F1 Score\n",
    "- Matriz de Confusión(TP, TN, FP, FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts_df = wf.predict_model_and_report(best_model_train_df, x_test_original_df, y_test_original_df, ['exitus', 'no exitus'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Guardamos las predicciones realizadas por el modelo para usarlas posteriormente en los Árboles de Decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts_deep = wf.predict_model_and_report(best_model_train_df, x_train_df, y_train_df, ['exitus', 'no exitus'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BASELINE NO NEURONALES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sobre los datos tras aplicar la reducción de características:\n",
    "- K Nearest Neigghbors\n",
    "- Support Vector Machine\n",
    "- Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf.knn_classifier(x_train_df, y_train_df, x_test_original_df, y_test_original_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf.svm_classifier(x_train_df, y_train_df, x_test_original_df, y_test_original_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf.lr_classifier(x_train_df, y_train_df, x_test_original_df, y_test_original_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Árboles de Decisión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CART: Implementación tradicional, entrenando el modelo jerárquico directamente sobre los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extraemos lo siguiente:\n",
    "- Obtención de las métricas de:\n",
    "    - Accuracy\n",
    "    - Precision\n",
    "    - Recall\n",
    "    - F1 Score\n",
    "- Matriz de Confusión(TP, TN, FP, FN)\n",
    "- Conjunto de reglas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cart_tree, cart_tree_rules, features = wf.cart_decision_tree(deep_features_drop, x_train_df, predicts_deep, x_test_original_df, y_test_original_df, 'entropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generación del plot con el árbol de decisión resultante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_graph = wf.plot_tree(cart_tree, features)\n",
    "Image(dt_graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TREPAN: Modelo jerárquico que utilizado el modelo neuronal y sus predicciones como complemento en el proceso de entrenamiento y predicción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creación del modelo jerárquico con los datos de entrenamiento y creación del modelo complementario basado en nuestro modelo neuronal y el conjunto de test que usará para ayudarse en el proceso de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = Interpretation(training_data=x_train_df, feature_names=features)\n",
    "im_model = InMemoryModel(best_model_train_df.predict, examples=x_test_original_df, feature_names=features, unique_values=[0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Instanciación del modelo completo al cual podemos establecer una profundidad máxima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate_explainer = TreeSurrogate(oracle=im_model, seed=42, max_depth=x_train_df.shape[1]-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Entrenamiento del modelo usando el modelo neuronal como ayuda. Podemos establecer se queremos que haga pre proda o post poda al explorar nodos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate_explainer.fit(x_train_df, predicts_deep, use_oracle=True, prune='pre')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicción sobre el conjunto de datos originales:\n",
    "- Obtención de las métricas de:\n",
    "    - Accuracy\n",
    "    - Precision\n",
    "    - Recall\n",
    "    - F1 Score\n",
    "- Matriz de Confusión(TP, TN, FP, FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = wf.predict_model_and_report(surrogate_explainer, x_test_original_df, y_test_original_df, ['exitus', 'no exitus'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Source(surrogate_explainer.plot_global_decisions(colors=['coral', 'darkturquoise'], \n",
    "                                          file_name='test_tree_pre.png').to_string())\n",
    "svg_data = graph.pipe(format='svg')\n",
    "with open('dtree_structure.svg','wb') as f:\n",
    "    f.write(svg_data)\n",
    "SVG(svg_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
